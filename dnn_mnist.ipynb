{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znacj1_tPBkV"
   },
   "source": [
    "# Entrenamiento de un Perceptrón Multi-Capa con datos de dígitos (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2509,
     "status": "ok",
     "timestamp": 1604749165965,
     "user": {
      "displayName": "Francisco Martínez",
      "photoUrl": "https://lh4.googleusercontent.com/-4m8RaiGue9o/AAAAAAAAAAI/AAAAAAAAILk/IXbBpxT3Cl8/s64/photo.jpg",
      "userId": "06734152272792166056"
     },
     "user_tz": -60
    },
    "id": "NVG6vDv-PGdh"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc2e63f1540f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs8yu5aLPNcT"
   },
   "source": [
    "## Carga de los datos\n",
    "#### Tamaño del conjunto de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afm41l6aPOrr"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data() #mnist reconoce escalas de grises entre\n",
    "\n",
    "print(' -Entradas Entrenamiento:', X_train.shape)\n",
    "print(' -Salidas Entrenamiento:', y_train.shape)\n",
    "print(' -Entradas Test:', X_test.shape)\n",
    "print(' -Salidas Test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMWlDrv9QnNU"
   },
   "source": [
    "#### Visualización de las entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuL9xI1oQo5y"
   },
   "outputs": [],
   "source": [
    "n_img_show = 3\n",
    "\n",
    "# Plot images\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(n_img_show):\n",
    "    plt.subplot(1, n_img_show, i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.colorbar(fraction=0.046)\n",
    "    plt.axis('off');\n",
    "\n",
    "print(f'Valores de salida correspondientes a las imágenes de entrada {y_train[0:n_img_show]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKhXvUoTRhcf"
   },
   "source": [
    "## Preparación de los datos\n",
    "#### Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51a4JJiNRkbO"
   },
   "outputs": [],
   "source": [
    "# Normalizamos a valores entre 0 y 1\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(n_img_show):\n",
    "    plt.subplot(1, n_img_show, i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.colorbar(fraction=0.046)\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPdCS0OeTAUS"
   },
   "source": [
    "#### Reajuste del tamaño de la entrada y la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDhNexDLTSXM"
   },
   "outputs": [],
   "source": [
    "x_shape = X_train.shape\n",
    "X_train = X_train.reshape(x_shape[0], x_shape[1]*x_shape[2])\n",
    "X_test = X_test.reshape(len(X_test), x_shape[1]*x_shape[2])\n",
    "y_train = y_train[:, None]\n",
    "y_test = y_test[:, None]\n",
    "\n",
    "# Dibujar la nueva entrada\n",
    "plt.figure(figsize=(20, 70))\n",
    "plt.imshow(X_train[0:100], cmap='gray')\n",
    "plt.xlabel('# Pixeles')\n",
    "plt.ylabel('# Imágenes')\n",
    "plt.colorbar(fraction=0.006);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYsJ7lKMS2aj"
   },
   "source": [
    "## Definición del modelo\n",
    "Crea un modelo con las siguientes capas:\n",
    "1. Capa de entrada con tantas entradas como número de píxeles (728) \n",
    "2. Capa oculta con 256 neuronas\n",
    "3. Capa oculta con 128 neuronas\n",
    "4. Capa oculta con 64 neuronas\n",
    "5. Capa oculta con 32 neuronas\n",
    "6. Capa de salidad con tantas neuronas como salidas (10)\n",
    "\n",
    "Todas las capas usan función de activación relu (menos la de salida). ¿Qué función de activación hay que poner a la salida?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21T25DcxS3RR"
   },
   "outputs": [],
   "source": [
    "# Algunos hiper-parámetros\n",
    "lr = .001\n",
    "batch_size = 512\n",
    "n_epochs = 35\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Crear modelo\n",
    "#    .\n",
    "#    .\n",
    "#    .\n",
    "\n",
    "# Visualizar arquitectura y dimensiones\n",
    "model.summary()\n",
    "\n",
    "# Compilamos el modelo: ¿Qué función de coste hay que utilizar?\n",
    "model.compile(loss='',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElwvPnL1ZUaa"
   },
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4SGVOpVY_mS"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, \n",
    "                 y_train, \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=n_epochs, \n",
    "                 verbose=1, \n",
    "                 shuffle=True,\n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVoAJhZfeGh8"
   },
   "source": [
    "### Dibujar las curvas de entrenamiento/validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCmUNmIseM4a"
   },
   "outputs": [],
   "source": [
    "def plot_curves(history):\n",
    "  plt.figure()\n",
    "  plt.xlabel('Épocas')\n",
    "  plt.ylabel('Error')\n",
    "  plt.plot(history['loss'])\n",
    "  plt.plot(history['val_loss'])\n",
    "  plt.legend(['Entrenamiento', 'Validación'])\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Épocas')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.plot(history['accuracy'])\n",
    "  plt.plot(history['val_accuracy'])\n",
    "  plt.legend(['Entrenamiento', 'Validación'], loc='lower right');\n",
    "\n",
    "plot_curves(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpSuRo2xuofk"
   },
   "source": [
    "### Visualización de los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0yFnP-Qadgm"
   },
   "outputs": [],
   "source": [
    "def plot_weights(model):\n",
    "  layers = [l for l in model.layers if l.name.startswith('dense')]\n",
    "  n_img_show = len(layers)\n",
    "  plt.figure(figsize=(30, 11))\n",
    "  cnt = 1\n",
    "  for layer in layers:\n",
    "      plt.subplot(1, n_img_show, cnt)\n",
    "      plt.imshow(layer.get_weights()[0])\n",
    "      plt.title(f'Pesos capa {cnt}')\n",
    "      plt.colorbar(fraction=0.07)\n",
    "      cnt += 1\n",
    "\n",
    "def plot_weights_hist(model):\n",
    "  layers = [l for l in model.layers if l.name.startswith('dense')]\n",
    "  n_img_show = len(layers)\n",
    "  plt.figure(figsize=(30, 5))\n",
    "  cnt = 1\n",
    "  for layer in layers:\n",
    "    if layer.name.startswith('dense'):\n",
    "      plt.subplot(1, n_img_show, cnt)\n",
    "      plt.hist(layer.get_weights()[0].flatten(), bins=30)\n",
    "      plt.title(f'Pesos capa {cnt}')\n",
    "      mean = np.mean(layer.get_weights()[0])\n",
    "      std = np.std(layer.get_weights()[0])\n",
    "      plt.xlabel(f'Valores de los pesos. Media: {mean:.3f} +- {std:.3f}')\n",
    "      plt.ylabel('cuenta')\n",
    "      cnt +=1\n",
    "\n",
    "plot_weights(model)\n",
    "plot_weights_hist(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuZOLQAZuufE"
   },
   "source": [
    "## Regularización del modelo con L2\n",
    "Crea un modelo nuevo exactamente igual que el anterior y añade regularización L2 en todas las capas (menos en la de salida, como es obvio). Prueba distintos valores (0.1, 0.01 y 0.001) y observa cual es el comportamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuZdUSZPuxxs"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "n_epochs = 50\n",
    "\n",
    "# Crear modelo\n",
    "#    .\n",
    "#    .\n",
    "#    .\n",
    "\n",
    "# Compilamos el modelo\n",
    "model_with_l2.compile(loss='',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos\n",
    "hist = model_with_l2.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=batch_size, \n",
    "                         epochs=n_epochs,\n",
    "                         verbose=1,\n",
    "                         shuffle=True, \n",
    "                         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_5UmBQcx77o"
   },
   "source": [
    "### Evaluación del modelo con regularización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBo3FWBKx_oP"
   },
   "outputs": [],
   "source": [
    "plot_curves(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX4VzCpXPWMc"
   },
   "source": [
    "### Visualización de los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faun7Mn5PZ8p"
   },
   "outputs": [],
   "source": [
    "plot_weights(model_with_l2)\n",
    "plot_weights_hist(model_with_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzVDtgsZQ3pK"
   },
   "source": [
    "## Regularización del modelo con Dropout\n",
    "Ahora crea el mismo modelo pero añade dropout. Prueba distintos valores de dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oN9kG-qQ2_b"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Crear modelo\n",
    "n_epochs = 25\n",
    "#    .\n",
    "#    .\n",
    "#    .\n",
    "\n",
    "# Compilamos el modelo\n",
    "model_with_dp.compile(loss='',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos\n",
    "hist = model_with_dp.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=batch_size, \n",
    "                         epochs=n_epochs,\n",
    "                         verbose=1, \n",
    "                         shuffle=True, \n",
    "                         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7owo4HtSdtS"
   },
   "source": [
    "### Evaluación del modelo con Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-e9LgArSSgua"
   },
   "outputs": [],
   "source": [
    "# Plots\n",
    "plot_curves(hist.history)\n",
    "# plot_weights(model_with_dp)\n",
    "plot_weights_hist(model_with_dp)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIDWIVS900MFm/DOcVVKkI",
   "collapsed_sections": [],
   "name": "dnn_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
